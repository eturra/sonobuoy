Flag --port has been deprecated, see --secure-port instead.
I0127 14:37:20.586435       1 serving.go:331] Generated self-signed cert in-memory
I0127 14:37:21.154083       1 controllermanager.go:176] Version: v1.20.0
I0127 14:37:21.155228       1 secure_serving.go:197] Serving securely on 127.0.0.1:10257
I0127 14:37:21.155296       1 leaderelection.go:243] attempting to acquire leader lease kube-system/kube-controller-manager...
I0127 14:37:21.155857       1 dynamic_cafile_content.go:167] Starting request-header::/etc/kubernetes/pki/front-proxy-ca.crt
I0127 14:37:21.155955       1 tlsconfig.go:240] Starting DynamicServingCertificateController
I0127 14:37:21.156150       1 dynamic_cafile_content.go:167] Starting client-ca-bundle::/etc/kubernetes/pki/ca.crt
E0127 14:37:24.707723       1 leaderelection.go:325] error retrieving resource lock kube-system/kube-controller-manager: leases.coordination.k8s.io "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-system"
I0127 14:37:27.522808       1 leaderelection.go:253] successfully acquired lease kube-system/kube-controller-manager
I0127 14:37:27.522987       1 event.go:291] "Event occurred" object="kube-system/kube-controller-manager" kind="Lease" apiVersion="coordination.k8s.io/v1" type="Normal" reason="LeaderElection" message="kind-control-plane_7d8c5637-9984-4434-a782-1f0ae3a091a7 became leader"
I0127 14:37:27.984760       1 shared_informer.go:240] Waiting for caches to sync for tokens
I0127 14:37:27.994727       1 controllermanager.go:554] Started "daemonset"
I0127 14:37:27.994776       1 daemon_controller.go:285] Starting daemon sets controller
I0127 14:37:27.994796       1 shared_informer.go:240] Waiting for caches to sync for daemon sets
I0127 14:37:28.003588       1 controllermanager.go:554] Started "job"
I0127 14:37:28.003782       1 job_controller.go:148] Starting job controller
I0127 14:37:28.003816       1 shared_informer.go:240] Waiting for caches to sync for job
I0127 14:37:28.022487       1 controllermanager.go:554] Started "horizontalpodautoscaling"
I0127 14:37:28.022673       1 horizontal.go:169] Starting HPA controller
I0127 14:37:28.022693       1 shared_informer.go:240] Waiting for caches to sync for HPA
I0127 14:37:28.032724       1 controllermanager.go:554] Started "ttl"
I0127 14:37:28.033133       1 ttl_controller.go:121] Starting TTL controller
I0127 14:37:28.033310       1 shared_informer.go:240] Waiting for caches to sync for TTL
E0127 14:37:28.042456       1 core.go:92] Failed to start service controller: WARNING: no cloud provider provided, services of type LoadBalancer will fail
W0127 14:37:28.042482       1 controllermanager.go:546] Skipping "service"
I0127 14:37:28.055008       1 controllermanager.go:554] Started "attachdetach"
I0127 14:37:28.055258       1 attach_detach_controller.go:328] Starting attach detach controller
I0127 14:37:28.055278       1 shared_informer.go:240] Waiting for caches to sync for attach detach
I0127 14:37:28.065526       1 controllermanager.go:554] Started "tokencleaner"
I0127 14:37:28.065721       1 tokencleaner.go:118] Starting token cleaner controller
I0127 14:37:28.065751       1 shared_informer.go:240] Waiting for caches to sync for token_cleaner
I0127 14:37:28.065767       1 shared_informer.go:247] Caches are synced for token_cleaner 
I0127 14:37:28.075618       1 controllermanager.go:554] Started "endpoint"
I0127 14:37:28.075795       1 endpoints_controller.go:184] Starting endpoint controller
I0127 14:37:28.075812       1 shared_informer.go:240] Waiting for caches to sync for endpoint
I0127 14:37:28.084998       1 shared_informer.go:247] Caches are synced for tokens 
I0127 14:37:28.087306       1 controllermanager.go:554] Started "endpointslicemirroring"
I0127 14:37:28.087487       1 endpointslicemirroring_controller.go:211] Starting EndpointSliceMirroring controller
I0127 14:37:28.087504       1 shared_informer.go:240] Waiting for caches to sync for endpoint_slice_mirroring
I0127 14:37:28.653052       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for replicasets.apps
I0127 14:37:28.653171       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for horizontalpodautoscalers.autoscaling
I0127 14:37:28.653214       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for limitranges
I0127 14:37:28.653419       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for statefulsets.apps
I0127 14:37:28.653471       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for podtemplates
I0127 14:37:28.653528       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for events.events.k8s.io
I0127 14:37:28.653598       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for roles.rbac.authorization.k8s.io
I0127 14:37:28.653651       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for endpointslices.discovery.k8s.io
I0127 14:37:28.653698       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for jobs.batch
I0127 14:37:28.653754       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for cronjobs.batch
I0127 14:37:28.653797       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for ingresses.networking.k8s.io
I0127 14:37:28.653847       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for poddisruptionbudgets.policy
I0127 14:37:28.653987       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for deployments.apps
I0127 14:37:28.654084       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for rolebindings.rbac.authorization.k8s.io
I0127 14:37:28.654158       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for controllerrevisions.apps
W0127 14:37:28.654201       1 shared_informer.go:494] resyncPeriod 14h26m15.549165315s is smaller than resyncCheckPeriod 17h22m2.465861608s and the informer has already started. Changing it to 17h22m2.465861608s
I0127 14:37:28.654425       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for serviceaccounts
I0127 14:37:28.654486       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for daemonsets.apps
I0127 14:37:28.654534       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for networkpolicies.networking.k8s.io
I0127 14:37:28.654595       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for ingresses.extensions
I0127 14:37:28.654656       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for endpoints
I0127 14:37:28.654792       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for leases.coordination.k8s.io
I0127 14:37:28.654845       1 controllermanager.go:554] Started "resourcequota"
I0127 14:37:28.654909       1 resource_quota_controller.go:273] Starting resource quota controller
I0127 14:37:28.655209       1 resource_quota_monitor.go:304] QuotaMonitor running
I0127 14:37:28.654956       1 shared_informer.go:240] Waiting for caches to sync for resource quota
I0127 14:37:28.664364       1 controllermanager.go:554] Started "serviceaccount"
I0127 14:37:28.664581       1 serviceaccounts_controller.go:117] Starting service account controller
I0127 14:37:28.664612       1 shared_informer.go:240] Waiting for caches to sync for service account
I0127 14:37:28.674970       1 controllermanager.go:554] Started "deployment"
I0127 14:37:28.675831       1 deployment_controller.go:153] Starting deployment controller
I0127 14:37:28.675915       1 shared_informer.go:240] Waiting for caches to sync for deployment
I0127 14:37:28.739656       1 controllermanager.go:554] Started "disruption"
I0127 14:37:28.739759       1 disruption.go:331] Starting disruption controller
I0127 14:37:28.739780       1 shared_informer.go:240] Waiting for caches to sync for disruption
I0127 14:37:28.890016       1 controllermanager.go:554] Started "bootstrapsigner"
I0127 14:37:28.890060       1 shared_informer.go:240] Waiting for caches to sync for bootstrap_signer
I0127 14:37:29.039220       1 node_lifecycle_controller.go:380] Sending events to api server.
I0127 14:37:29.039467       1 taint_manager.go:163] Sending events to api server.
I0127 14:37:29.039584       1 node_lifecycle_controller.go:508] Controller will reconcile labels.
I0127 14:37:29.039641       1 controllermanager.go:554] Started "nodelifecycle"
I0127 14:37:29.039734       1 node_lifecycle_controller.go:542] Starting node controller
I0127 14:37:29.039762       1 shared_informer.go:240] Waiting for caches to sync for taint
I0127 14:37:29.192712       1 controllermanager.go:554] Started "persistentvolume-binder"
W0127 14:37:29.192861       1 controllermanager.go:546] Skipping "ttl-after-finished"
I0127 14:37:29.193404       1 pv_controller_base.go:307] Starting persistent volume controller
I0127 14:37:29.193504       1 shared_informer.go:240] Waiting for caches to sync for persistent volume
I0127 14:37:29.340772       1 controllermanager.go:554] Started "podgc"
I0127 14:37:29.340873       1 gc_controller.go:89] Starting GC controller
I0127 14:37:29.340889       1 shared_informer.go:240] Waiting for caches to sync for GC
I0127 14:37:29.489351       1 controllermanager.go:554] Started "clusterrole-aggregation"
I0127 14:37:29.489468       1 clusterroleaggregation_controller.go:149] Starting ClusterRoleAggregator
I0127 14:37:29.489483       1 shared_informer.go:240] Waiting for caches to sync for ClusterRoleAggregator
I0127 14:37:29.643037       1 controllermanager.go:554] Started "pvc-protection"
I0127 14:37:29.643136       1 pvc_protection_controller.go:110] Starting PVC protection controller
I0127 14:37:29.643362       1 shared_informer.go:240] Waiting for caches to sync for PVC protection
I0127 14:37:29.790084       1 controllermanager.go:554] Started "pv-protection"
W0127 14:37:29.790223       1 controllermanager.go:546] Skipping "ephemeral-volume"
I0127 14:37:29.790281       1 pv_protection_controller.go:83] Starting PV protection controller
I0127 14:37:29.790304       1 shared_informer.go:240] Waiting for caches to sync for PV protection
I0127 14:37:29.801232       1 request.go:655] Throttling request took 1.0479963s, request: GET:https://172.18.0.4:6443/apis/storage.k8s.io/v1?timeout=32s
I0127 14:37:29.943007       1 controllermanager.go:554] Started "replicationcontroller"
I0127 14:37:29.943182       1 replica_set.go:182] Starting replicationcontroller controller
I0127 14:37:29.943208       1 shared_informer.go:240] Waiting for caches to sync for ReplicationController
I0127 14:37:30.089535       1 controllermanager.go:554] Started "replicaset"
I0127 14:37:30.089648       1 replica_set.go:182] Starting replicaset controller
I0127 14:37:30.089683       1 shared_informer.go:240] Waiting for caches to sync for ReplicaSet
I0127 14:37:30.239111       1 controllermanager.go:554] Started "csrapproving"
I0127 14:37:30.239205       1 certificate_controller.go:118] Starting certificate controller "csrapproving"
I0127 14:37:30.239220       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrapproving
I0127 14:37:30.288365       1 controllermanager.go:554] Started "csrcleaner"
I0127 14:37:30.288492       1 cleaner.go:82] Starting CSR cleaner controller
I0127 14:37:30.338025       1 node_ipam_controller.go:91] Sending events to api server.
I0127 14:37:40.325223       1 range_allocator.go:82] Sending events to api server.
I0127 14:37:40.325393       1 range_allocator.go:116] No Secondary Service CIDR provided. Skipping filtering out secondary service addresses.
I0127 14:37:40.325469       1 controllermanager.go:554] Started "nodeipam"
I0127 14:37:40.325637       1 node_ipam_controller.go:159] Starting ipam controller
I0127 14:37:40.325670       1 shared_informer.go:240] Waiting for caches to sync for node
I0127 14:37:40.328142       1 node_lifecycle_controller.go:77] Sending events to api server
E0127 14:37:40.328197       1 core.go:232] failed to start cloud node lifecycle controller: no cloud provider provided
W0127 14:37:40.328246       1 controllermanager.go:546] Skipping "cloud-node-lifecycle"
I0127 14:37:40.366325       1 controllermanager.go:554] Started "namespace"
I0127 14:37:40.366458       1 namespace_controller.go:200] Starting namespace controller
I0127 14:37:40.366494       1 shared_informer.go:240] Waiting for caches to sync for namespace
I0127 14:37:40.369816       1 certificate_controller.go:118] Starting certificate controller "csrsigning-kubelet-serving"
I0127 14:37:40.369860       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-kubelet-serving
I0127 14:37:40.369860       1 dynamic_serving_content.go:130] Starting csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key
I0127 14:37:40.370301       1 certificate_controller.go:118] Starting certificate controller "csrsigning-kubelet-client"
I0127 14:37:40.370336       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-kubelet-client
I0127 14:37:40.370336       1 dynamic_serving_content.go:130] Starting csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key
I0127 14:37:40.371113       1 certificate_controller.go:118] Starting certificate controller "csrsigning-kube-apiserver-client"
I0127 14:37:40.371149       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-kube-apiserver-client
I0127 14:37:40.371202       1 dynamic_serving_content.go:130] Starting csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key
I0127 14:37:40.371835       1 controllermanager.go:554] Started "csrsigning"
W0127 14:37:40.371869       1 core.go:246] configure-cloud-routes is set, but no cloud provider specified. Will not configure cloud provider routes.
I0127 14:37:40.371941       1 certificate_controller.go:118] Starting certificate controller "csrsigning-legacy-unknown"
I0127 14:37:40.371953       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-legacy-unknown
I0127 14:37:40.371984       1 dynamic_serving_content.go:130] Starting csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key
W0127 14:37:40.371884       1 controllermanager.go:546] Skipping "route"
I0127 14:37:40.380343       1 controllermanager.go:554] Started "statefulset"
I0127 14:37:40.380392       1 stateful_set.go:146] Starting stateful set controller
I0127 14:37:40.380409       1 shared_informer.go:240] Waiting for caches to sync for stateful set
I0127 14:37:40.389943       1 controllermanager.go:554] Started "cronjob"
I0127 14:37:40.390202       1 cronjob_controller.go:96] Starting CronJob Manager
I0127 14:37:40.401127       1 controllermanager.go:554] Started "persistentvolume-expander"
I0127 14:37:40.401164       1 expand_controller.go:310] Starting expand controller
I0127 14:37:40.401182       1 shared_informer.go:240] Waiting for caches to sync for expand
I0127 14:37:40.412564       1 controllermanager.go:554] Started "endpointslice"
I0127 14:37:40.412739       1 endpointslice_controller.go:237] Starting endpoint slice controller
I0127 14:37:40.412822       1 shared_informer.go:240] Waiting for caches to sync for endpoint_slice
I0127 14:37:40.424869       1 controllermanager.go:554] Started "garbagecollector"
I0127 14:37:40.424901       1 garbagecollector.go:142] Starting garbage collector controller
I0127 14:37:40.424921       1 shared_informer.go:240] Waiting for caches to sync for garbage collector
I0127 14:37:40.424971       1 graph_builder.go:289] GraphBuilder running
I0127 14:37:40.436594       1 controllermanager.go:554] Started "root-ca-cert-publisher"
I0127 14:37:40.436891       1 shared_informer.go:240] Waiting for caches to sync for resource quota
I0127 14:37:40.437039       1 publisher.go:98] Starting root CA certificate configmap publisher
I0127 14:37:40.437069       1 shared_informer.go:240] Waiting for caches to sync for crt configmap
W0127 14:37:40.455108       1 actual_state_of_world.go:506] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="kind-control-plane" does not exist
I0127 14:37:40.455215       1 shared_informer.go:247] Caches are synced for ClusterRoleAggregator 
I0127 14:37:40.455441       1 shared_informer.go:247] Caches are synced for ReplicaSet 
I0127 14:37:40.455766       1 shared_informer.go:247] Caches are synced for bootstrap_signer 
I0127 14:37:40.456132       1 shared_informer.go:247] Caches are synced for PV protection 
I0127 14:37:40.460160       1 shared_informer.go:247] Caches are synced for persistent volume 
I0127 14:37:40.460734       1 shared_informer.go:247] Caches are synced for daemon sets 
I0127 14:37:40.467026       1 shared_informer.go:247] Caches are synced for namespace 
I0127 14:37:40.470462       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-kubelet-client 
I0127 14:37:40.470566       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-kubelet-serving 
I0127 14:37:40.470639       1 shared_informer.go:247] Caches are synced for job 
I0127 14:37:40.471945       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-kube-apiserver-client 
I0127 14:37:40.472052       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-legacy-unknown 
I0127 14:37:40.499353       1 shared_informer.go:247] Caches are synced for TTL 
I0127 14:37:40.501564       1 shared_informer.go:247] Caches are synced for expand 
I0127 14:37:40.504965       1 shared_informer.go:247] Caches are synced for certificate-csrapproving 
I0127 14:37:40.506666       1 shared_informer.go:247] Caches are synced for GC 
I0127 14:37:40.509048       1 shared_informer.go:247] Caches are synced for ReplicationController 
I0127 14:37:40.509208       1 shared_informer.go:247] Caches are synced for PVC protection 
I0127 14:37:40.521134       1 shared_informer.go:247] Caches are synced for attach detach 
I0127 14:37:40.525869       1 shared_informer.go:247] Caches are synced for node 
I0127 14:37:40.525937       1 range_allocator.go:172] Starting range CIDR allocator
I0127 14:37:40.525955       1 shared_informer.go:240] Waiting for caches to sync for cidrallocator
I0127 14:37:40.525970       1 shared_informer.go:247] Caches are synced for cidrallocator 
I0127 14:37:40.530876       1 shared_informer.go:247] Caches are synced for service account 
I0127 14:37:40.530929       1 range_allocator.go:373] Set node kind-control-plane PodCIDR to [10.244.0.0/24]
I0127 14:37:40.537318       1 shared_informer.go:247] Caches are synced for crt configmap 
I0127 14:37:40.541710       1 shared_informer.go:247] Caches are synced for deployment 
I0127 14:37:40.580746       1 shared_informer.go:247] Caches are synced for stateful set 
I0127 14:37:40.605684       1 shared_informer.go:247] Caches are synced for disruption 
I0127 14:37:40.605722       1 disruption.go:339] Sending events to api server.
I0127 14:37:40.613489       1 shared_informer.go:247] Caches are synced for endpoint_slice 
I0127 14:37:40.641852       1 shared_informer.go:247] Caches are synced for endpoint 
I0127 14:37:40.653375       1 shared_informer.go:247] Caches are synced for endpoint_slice_mirroring 
I0127 14:37:40.688647       1 shared_informer.go:247] Caches are synced for HPA 
I0127 14:37:40.705433       1 shared_informer.go:247] Caches are synced for taint 
I0127 14:37:40.705556       1 taint_manager.go:187] Starting NoExecuteTaintManager
I0127 14:37:40.705567       1 node_lifecycle_controller.go:1429] Initializing eviction metric for zone: 
W0127 14:37:40.705615       1 node_lifecycle_controller.go:1044] Missing timestamp for Node kind-control-plane. Assuming now as a timestamp.
I0127 14:37:40.705723       1 node_lifecycle_controller.go:1195] Controller detected that all Nodes are not-Ready. Entering master disruption mode.
I0127 14:37:40.705931       1 event.go:291] "Event occurred" object="kind-control-plane" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node kind-control-plane event: Registered Node kind-control-plane in Controller"
I0127 14:37:40.721347       1 shared_informer.go:247] Caches are synced for resource quota 
I0127 14:37:40.737437       1 shared_informer.go:247] Caches are synced for resource quota 
I0127 14:37:40.971857       1 event.go:291] "Event occurred" object="kube-system/kube-proxy" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-lrtdp"
I0127 14:37:40.973666       1 event.go:291] "Event occurred" object="kube-system/kindnet" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kindnet-qhzxn"
I0127 14:37:41.318491       1 event.go:291] "Event occurred" object="kube-system/coredns" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-74ff55c5b to 2"
I0127 14:37:41.319512       1 event.go:291] "Event occurred" object="local-path-storage/local-path-provisioner" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set local-path-provisioner-78776bfc44 to 1"
I0127 14:37:41.336105       1 shared_informer.go:240] Waiting for caches to sync for garbage collector
I0127 14:37:41.425123       1 shared_informer.go:247] Caches are synced for garbage collector 
I0127 14:37:41.425246       1 garbagecollector.go:151] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
I0127 14:37:41.436661       1 shared_informer.go:247] Caches are synced for garbage collector 
I0127 14:37:41.518062       1 event.go:291] "Event occurred" object="kube-system/coredns-74ff55c5b" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-74ff55c5b-vk77h"
I0127 14:37:41.523442       1 event.go:291] "Event occurred" object="local-path-storage/local-path-provisioner-78776bfc44" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: local-path-provisioner-78776bfc44-66xwg"
I0127 14:37:41.527628       1 event.go:291] "Event occurred" object="kube-system/coredns-74ff55c5b" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-74ff55c5b-cpfqs"
W0127 14:37:53.011720       1 actual_state_of_world.go:506] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="kind-worker2" does not exist
I0127 14:37:53.025404       1 event.go:291] "Event occurred" object="kube-system/kindnet" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kindnet-hknk7"
I0127 14:37:53.025448       1 event.go:291] "Event occurred" object="kube-system/kube-proxy" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-8jj5r"
I0127 14:37:53.038383       1 range_allocator.go:373] Set node kind-worker2 PodCIDR to [10.244.1.0/24]
E0127 14:37:53.049335       1 daemon_controller.go:320] kube-system/kindnet failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kindnet", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"d67ab0dc-4966-4d8a-896d-32b3fddedac7", ResourceVersion:"474", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63778891050, loc:(*time.Location)(0x3bd0380)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"kindnet", "k8s-app":"kindnet", "tier":"node"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"kubectl-create", Operation:"Update", APIVersion:"apps/v1", Time:(*v1.Time)(0xc0011602c0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0011602e0)}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"apps/v1", Time:(*v1.Time)(0xc001160300), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001160320)}}}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc001160340), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"kindnet", "k8s-app":"kindnet", "tier":"node"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"cni-cfg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001160360), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}, v1.Volume{Name:"xtables-lock", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001160380), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}, v1.Volume{Name:"lib-modules", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0011603a0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"kindnet-cni", Image:"kindest/kindnetd:v20200725-4d6bea59", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"HOST_IP", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0011603c0)}, v1.EnvVar{Name:"POD_IP", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001160400)}, v1.EnvVar{Name:"POD_SUBNET", Value:"10.244.0.0/16", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"cni-cfg", ReadOnly:false, MountPath:"/etc/cni/net.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"xtables-lock", ReadOnly:false, MountPath:"/run/xtables.lock", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"lib-modules", ReadOnly:true, MountPath:"/lib/modules", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc001239380), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0005e0dd8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"kindnet", DeprecatedServiceAccount:"kindnet", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00042af50), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc000fbc1e0)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc0005e0e80)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:1, NumberMisscheduled:0, DesiredNumberScheduled:1, NumberReady:1, ObservedGeneration:1, UpdatedNumberScheduled:1, NumberAvailable:1, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "kindnet": the object has been modified; please apply your changes to the latest version and try again
W0127 14:37:53.166095       1 actual_state_of_world.go:506] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="kind-worker" does not exist
I0127 14:37:53.172233       1 event.go:291] "Event occurred" object="kube-system/kube-proxy" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-g79v6"
I0127 14:37:53.176770       1 event.go:291] "Event occurred" object="kube-system/kindnet" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kindnet-x9fsq"
I0127 14:37:53.188500       1 range_allocator.go:373] Set node kind-worker PodCIDR to [10.244.2.0/24]
E0127 14:37:53.214905       1 daemon_controller.go:320] kube-system/kube-proxy failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-proxy", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"b4048472-c00f-4ae8-a223-8d29ef5133c0", ResourceVersion:"508", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63778891048, loc:(*time.Location)(0x3bd0380)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"kube-proxy"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"kubeadm", Operation:"Update", APIVersion:"apps/v1", Time:(*v1.Time)(0xc001148860), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc001148880)}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"apps/v1", Time:(*v1.Time)(0xc0011488a0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0011488c0)}}}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc0011488e0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"kube-proxy"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-proxy", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc001e8f700), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}, v1.Volume{Name:"xtables-lock", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001148900), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}, v1.Volume{Name:"lib-modules", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001148920), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"kube-proxy", Image:"k8s.gcr.io/kube-proxy:v1.20.0", Command:[]string{"/usr/local/bin/kube-proxy", "--config=/var/lib/kube-proxy/config.conf", "--hostname-override=$(NODE_NAME)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001148aa0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-proxy", ReadOnly:false, MountPath:"/var/lib/kube-proxy", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"xtables-lock", ReadOnly:false, MountPath:"/run/xtables.lock", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"lib-modules", ReadOnly:true, MountPath:"/lib/modules", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc00194f020), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002069ef8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"kubernetes.io/os":"linux"}, ServiceAccountName:"kube-proxy", DeprecatedServiceAccount:"kube-proxy", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00034c230), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc000490c98)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc002069f48)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:2, NumberMisscheduled:0, DesiredNumberScheduled:2, NumberReady:1, ObservedGeneration:1, UpdatedNumberScheduled:2, NumberAvailable:1, NumberUnavailable:1, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "kube-proxy": the object has been modified; please apply your changes to the latest version and try again
I0127 14:37:55.707643       1 event.go:291] "Event occurred" object="kind-worker" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node kind-worker event: Registered Node kind-worker in Controller"
W0127 14:37:55.707575       1 node_lifecycle_controller.go:1044] Missing timestamp for Node kind-worker. Assuming now as a timestamp.
I0127 14:37:55.707908       1 event.go:291] "Event occurred" object="kind-worker2" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node kind-worker2 event: Registered Node kind-worker2 in Controller"
W0127 14:37:55.708174       1 node_lifecycle_controller.go:1044] Missing timestamp for Node kind-worker2. Assuming now as a timestamp.
I0127 14:37:55.708425       1 node_lifecycle_controller.go:1222] Controller detected that some Nodes are Ready. Exiting master disruption mode.
E0127 14:42:29.598699       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
E0127 14:42:29.752972       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
E0127 14:42:29.917862       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
E0127 14:42:30.095871       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
E0127 14:42:30.292984       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
E0127 14:42:30.584859       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
E0127 14:42:30.912665       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
E0127 14:42:31.388983       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
E0127 14:42:32.175050       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
E0127 14:42:33.593576       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
E0127 14:42:36.356292       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
E0127 14:42:41.628183       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
E0127 14:42:52.025904       1 namespace_controller.go:162] deletion of namespace sonobuoy failed: unexpected items still remain in namespace: sonobuoy for gvr: /v1, Resource=pods
I0127 14:43:17.631385       1 namespace_controller.go:185] Namespace has been deleted sonobuoy
I0127 14:43:37.588904       1 event.go:291] "Event occurred" object="sonobuoy/sonobuoy-systemd-logs-daemon-set-7a10f4effeb44d32" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: sonobuoy-systemd-logs-daemon-set-7a10f4effeb44d32-jrn9s"
I0127 14:43:37.598184       1 event.go:291] "Event occurred" object="sonobuoy/sonobuoy-systemd-logs-daemon-set-7a10f4effeb44d32" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: sonobuoy-systemd-logs-daemon-set-7a10f4effeb44d32-7n2cj"
I0127 14:43:37.602269       1 event.go:291] "Event occurred" object="sonobuoy/sonobuoy-systemd-logs-daemon-set-7a10f4effeb44d32" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: sonobuoy-systemd-logs-daemon-set-7a10f4effeb44d32-zqfjc"
E0127 14:43:37.640390       1 daemon_controller.go:320] sonobuoy/sonobuoy-systemd-logs-daemon-set-7a10f4effeb44d32 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"sonobuoy-systemd-logs-daemon-set-7a10f4effeb44d32", GenerateName:"", Namespace:"sonobuoy", SelfLink:"", UID:"27c46bd0-b139-486f-ac07-df0d9c665547", ResourceVersion:"1387", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63778891417, loc:(*time.Location)(0x3bd0380)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"component":"sonobuoy", "sonobuoy-component":"plugin", "sonobuoy-plugin":"systemd-logs", "sonobuoy-run":"7a10f4effeb44d32", "tier":"analysis"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "sonobuoy-driver":"DaemonSet", "sonobuoy-plugin":"systemd-logs"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"sonobuoy", UID:"01c6daf3-1338-4766-9081-518eda1d596f", Controller:(*bool)(nil), BlockOwnerDeletion:(*bool)(nil)}}, Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"sonobuoy", Operation:"Update", APIVersion:"apps/v1", Time:(*v1.Time)(0xc002334340), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002334360)}}}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc002334380), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"component":"sonobuoy", "sonobuoy-component":"plugin", "sonobuoy-plugin":"systemd-logs", "sonobuoy-run":"7a10f4effeb44d32", "tier":"analysis"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"root", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0023343a0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}, v1.Volume{Name:"results", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(0xc0023343c0), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"systemd-logs", Image:"sonobuoy/systemd-logs:v0.4", Command:[]string{"/bin/sh", "-c", "/get_systemd_logs.sh; while true; do echo \"Plugin is complete. Sleeping indefinitely to avoid container exit and automatic restarts from Kubernetes\"; sleep 3600; done"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"CHROOT_DIR", Value:"/node", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc002334400)}, v1.EnvVar{Name:"RESULTS_DIR", Value:"/tmp/sonobuoy/results", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"SONOBUOY", Value:"true", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"SONOBUOY_CONFIG_DIR", Value:"/tmp/sonobuoy/config", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"SONOBUOY_K8S_VERSION", Value:"v1.20.0", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"SONOBUOY_PROGRESS_PORT", Value:"8099", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"SONOBUOY_RESULTS_DIR", Value:"/tmp/sonobuoy/results", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"root", ReadOnly:false, MountPath:"/node", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"results", ReadOnly:false, MountPath:"/tmp/sonobuoy/results", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc001fe00c0), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"sonobuoy-worker", Image:"sonobuoy/sonobuoy:v0.56.0", Command:[]string{"/sonobuoy", "worker", "single-node", "--level=trace", "-v=6", "--logtostderr", "--sleep=-1"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc002334460)}, v1.EnvVar{Name:"RESULTS_DIR", Value:"/tmp/sonobuoy/results", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"SONOBUOY_RESULTS_DIR", Value:"/tmp/sonobuoy/results", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"RESULT_TYPE", Value:"systemd-logs", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"AGGREGATOR_URL", Value:"https://[10.244.1.3]:8080", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"CA_CERT", Value:"-----BEGIN CERTIFICATE-----\nMIIB3TCCAYOgAwIBAgIBATAKBggqhkjOPQQDAjBKMQwwCgYDVQQGEwNVU0ExFjAU\nBgNVBAcTDVBhbG8gQWx0bywgQ0ExDzANBgNVBAoTBlZNd2FyZTERMA8GA1UECxMI\nU29ub2J1b3kwHhcNMjIwMTI3MTQ0MzM3WhcNMjIwMTI5MTQ0MzM3WjBKMQwwCgYD\nVQQGEwNVU0ExFjAUBgNVBAcTDVBhbG8gQWx0bywgQ0ExDzANBgNVBAoTBlZNd2Fy\nZTERMA8GA1UECxMIU29ub2J1b3kwWTATBgcqhkjOPQIBBggqhkjOPQMBBwNCAATe\n/K+tlJpWtZHc2PfDdnQjxOw5HQHi4vBnUcxlR33asCf6KgQkB4pv0yuPqHEBohsc\nH/GVFKgituuF7PCVGTGbo1owWDAOBgNVHQ8BAf8EBAMCAgQwDwYDVR0TAQH/BAUw\nAwEB/zAdBgNVHQ4EFgQUTcUn+/q96i0IIfJt7QPKrgfnNdYwFgYDVR0RBA8wDYIL\nc29ub2J1b3ktY2EwCgYIKoZIzj0EAwIDSAAwRQIgbdyEzN9Z5qsfgZqYTA7JdHfk\nH0FqI/W63hW6LZ7OBFYCIQCeAfdBeqCSWMsQp1rAqmExhKEl7wzLW5fpna8eF+2A\nVQ==\n-----END CERTIFICATE-----\n", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"CLIENT_CERT", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0023344a0)}, v1.EnvVar{Name:"CLIENT_KEY", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0023344c0)}, v1.EnvVar{Name:"SONOBUOY_PROGRESS_PORT", Value:"8099", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"SONOBUOY_DIR", Value:"/tmp/sonobuoy", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"SONOBUOY_NS", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0023344e0)}, v1.EnvVar{Name:"SONOBUOY_PLUGIN_POD", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc002334520)}, v1.EnvVar{Name:"SONOBUOY_WORKER_CONTAINER", Value:"sonobuoy-worker", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"results", ReadOnly:false, MountPath:"/tmp/sonobuoy/results", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0020fd288), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirstWithHostNet", NodeSelector:map[string]string{"kubernetes.io/os":"linux"}, ServiceAccountName:"sonobuoy-serviceaccount", DeprecatedServiceAccount:"sonobuoy-serviceaccount", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:true, HostIPC:true, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0000f2070), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc0009b0858)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc0020fd2ac)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:0, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "sonobuoy-systemd-logs-daemon-set-7a10f4effeb44d32": the object has been modified; please apply your changes to the latest version and try again
